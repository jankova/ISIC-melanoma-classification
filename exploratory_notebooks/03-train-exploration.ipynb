{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b82af458",
   "metadata": {},
   "source": [
    "### Check current version of tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cbf478c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4501800f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecd8660",
   "metadata": {},
   "source": [
    "#### Update tensorflow to 2.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e4d2f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.3.0\n",
      "  Downloading tensorflow-2.3.0-cp36-cp36m-manylinux2010_x86_64.whl (320.4 MB)\n",
      "\u001b[K     |███████████████████████████▍    | 274.4 MB 147.8 MB/s eta 0:00:01"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 320.4 MB 43 kB/s \n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.3.0) (3.19.1)\n",
      "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
      "  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
      "\u001b[K     |████████████████████████████████| 459 kB 117.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.3.0) (1.12.1)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.3.0) (2.10.0)\n",
      "Collecting keras-preprocessing<1.2,>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 2.5 MB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.3.0) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.3.0) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.3.0) (1.41.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.3.0) (0.14.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.3.0) (0.2.0)\n",
      "Collecting astunparse==1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorboard<3,>=2.3.0\n",
      "  Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 57.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.3.0) (0.36.2)\n",
      "Collecting scipy==1.4.1\n",
      "  Downloading scipy-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (26.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.1 MB 57.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorflow==2.3.0) (1.16.0)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting numpy<1.19.0,>=1.16.0\n",
      "  Downloading numpy-1.18.5-cp36-cp36m-manylinux1_x86_64.whl (20.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.1 MB 120.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 58.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.6)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 128.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.26.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.35.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (58.5.3)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.8.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.10.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.6.0)\n",
      "Installing collected packages: tensorboard-plugin-wit, tensorboard-data-server, numpy, tensorflow-estimator, tensorboard, scipy, keras-preprocessing, gast, astunparse, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.1.0\n",
      "    Uninstalling tensorflow-estimator-2.1.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.1.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.1.1\n",
      "    Uninstalling tensorboard-2.1.1:\n",
      "      Successfully uninstalled tensorboard-2.1.1\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.5.3\n",
      "    Uninstalling scipy-1.5.3:\n",
      "      Successfully uninstalled scipy-1.5.3\n",
      "  Attempting uninstall: keras-preprocessing\n",
      "    Found existing installation: Keras-Preprocessing 1.1.0\n",
      "    Uninstalling Keras-Preprocessing-1.1.0:\n",
      "      Successfully uninstalled Keras-Preprocessing-1.1.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.2.2\n",
      "    Uninstalling gast-0.2.2:\n",
      "      Successfully uninstalled gast-0.2.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-serving-api 2.1.0 requires tensorflow~=2.1.0, but you have tensorflow 2.3.0 which is incompatible.\n",
      "tensorflow-gpu 2.1.3 requires gast==0.2.2, but you have gast 0.3.3 which is incompatible.\n",
      "tensorflow-gpu 2.1.3 requires keras-preprocessing==1.1.0, but you have keras-preprocessing 1.1.2 which is incompatible.\n",
      "tensorflow-gpu 2.1.3 requires tensorboard<2.2.0,>=2.1.0, but you have tensorboard 2.7.0 which is incompatible.\n",
      "tensorflow-gpu 2.1.3 requires tensorflow-estimator<2.2.0,>=2.1.0rc0, but you have tensorflow-estimator 2.3.0 which is incompatible.\u001b[0m\n",
      "Successfully installed astunparse-1.6.3 gast-0.3.3 keras-preprocessing-1.1.2 numpy-1.18.5 scipy-1.4.1 tensorboard-2.7.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.3.0 tensorflow-estimator-2.3.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/tensorflow2_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow==2.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d5423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart kernel after update \n",
    "import os\n",
    "os._exit(00)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b48d29f",
   "metadata": {},
   "source": [
    "# Load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "000b8b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd3eba76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81c8c6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2d70e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 150\n",
    "IMG_HEIGHT = 150\n",
    "\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "469f3502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13656 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "data_dir_train = 'data/processed/train/'\n",
    "data_dir_test = 'data/processed/test/'\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir_train,\n",
    "    labels = \"inferred\",\n",
    "    validation_split = 0.0,\n",
    "    #shuffle = True,\n",
    "    seed = 42,\n",
    "    #subset = \"training\",\n",
    "    batch_size = BATCH_SIZE,\n",
    "    image_size = (IMG_WIDTH, IMG_HEIGHT)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1eb4560",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "#val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#    data_dir_train,\n",
    "#    labels = \"inferred\",\n",
    "#    validation_split = 0.2,\n",
    "#    shuffle = True,\n",
    "#    seed = 42, \n",
    "#    subset = \"validation\",\n",
    "#    batch_size = BATCH_SIZE,\n",
    "#    image_size = (IMG_WIDTH, IMG_HEIGHT)\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b4e6cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1537 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir_test,\n",
    "    labels = \"inferred\",\n",
    "    validation_split = 0.0,\n",
    "    shuffle = False,\n",
    "    seed = 42, \n",
    "    batch_size = BATCH_SIZE,\n",
    "    image_size = (IMG_WIDTH, IMG_HEIGHT)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78b0dd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for item in val_ds:\n",
    "#    print(item)\n",
    "#    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb38225",
   "metadata": {},
   "source": [
    "# VGG16\n",
    "We explore different variations and sizes of VGG with pretrained weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6111e35f",
   "metadata": {},
   "source": [
    "## VGG16 retrained on last 3 dense layers + dropout regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c47f17f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.models_vgg16 import VGG16, VGG16aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5567c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model_vgg16 = VGG16(IMG_WIDTH, IMG_HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "778b4a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [tf.keras.metrics.AUC(name = \"AUC\"), \n",
    "           tf.keras.metrics.BinaryAccuracy(name = \"accuracy\"), \n",
    "           tf.keras.metrics.Precision(name = \"precision\"),\n",
    "           tf.keras.metrics.Recall(name = \"recall\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39ac5858",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "\n",
    "model_vgg16.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = lr),\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(from_logits = False), #BinaryCrossentropy(from_logits = False),\n",
    "    metrics = METRICS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e58ab0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "427/427 [==============================] - 122s 287ms/step - loss: 9.1716 - AUC: 0.7390 - accuracy: 0.7464 - precision: 0.5523 - recall: 0.5112 - val_loss: 5.8180 - val_AUC: 0.7176 - val_accuracy: 0.8725 - val_precision: 0.2414 - val_recall: 0.0387\n",
      "Epoch 2/3\n",
      "427/427 [==============================] - 121s 283ms/step - loss: 4.4816 - AUC: 0.8292 - accuracy: 0.7994 - precision: 0.6760 - recall: 0.5480 - val_loss: 3.2399 - val_AUC: 0.7658 - val_accuracy: 0.8770 - val_precision: 0.4000 - val_recall: 0.0884\n",
      "Epoch 3/3\n",
      "427/427 [==============================] - 121s 283ms/step - loss: 2.5721 - AUC: 0.8592 - accuracy: 0.8162 - precision: 0.7201 - recall: 0.5649 - val_loss: 1.8787 - val_AUC: 0.7959 - val_accuracy: 0.8796 - val_precision: 0.4444 - val_recall: 0.0884\n"
     ]
    }
   ],
   "source": [
    "initial_epochs = 3\n",
    "history_vgg16 = model_vgg16.fit(train_ds, epochs = initial_epochs, validation_data = val_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7d56a305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "427/427 [==============================] - 121s 283ms/step - loss: 1.6413 - AUC: 0.8703 - accuracy: 0.8237 - precision: 0.7324 - recall: 0.5861 - val_loss: 1.2525 - val_AUC: 0.7976 - val_accuracy: 0.8829 - val_precision: 0.5185 - val_recall: 0.0773\n",
      "Epoch 2/7\n",
      "427/427 [==============================] - 120s 282ms/step - loss: 1.1286 - AUC: 0.8747 - accuracy: 0.8237 - precision: 0.7348 - recall: 0.5819 - val_loss: 0.8775 - val_AUC: 0.8039 - val_accuracy: 0.8796 - val_precision: 0.4286 - val_recall: 0.0663\n",
      "Epoch 3/7\n",
      "427/427 [==============================] - 121s 282ms/step - loss: 0.8527 - AUC: 0.8813 - accuracy: 0.8281 - precision: 0.7464 - recall: 0.5874 - val_loss: 0.7075 - val_AUC: 0.7978 - val_accuracy: 0.8738 - val_precision: 0.4110 - val_recall: 0.1657\n",
      "Epoch 4/7\n",
      "427/427 [==============================] - 120s 282ms/step - loss: 0.7285 - AUC: 0.8808 - accuracy: 0.8316 - precision: 0.7506 - recall: 0.5996 - val_loss: 0.6004 - val_AUC: 0.8049 - val_accuracy: 0.8764 - val_precision: 0.4400 - val_recall: 0.1823\n",
      "Epoch 5/7\n",
      "427/427 [==============================] - 121s 282ms/step - loss: 0.6599 - AUC: 0.8763 - accuracy: 0.8275 - precision: 0.7449 - recall: 0.5863 - val_loss: 0.5558 - val_AUC: 0.7996 - val_accuracy: 0.8816 - val_precision: 0.4800 - val_recall: 0.0663\n",
      "Epoch 6/7\n",
      "427/427 [==============================] - 121s 283ms/step - loss: 0.6115 - AUC: 0.8792 - accuracy: 0.8267 - precision: 0.7412 - recall: 0.5879 - val_loss: 0.5182 - val_AUC: 0.7974 - val_accuracy: 0.8777 - val_precision: 0.4386 - val_recall: 0.1381\n",
      "Epoch 7/7\n",
      "427/427 [==============================] - 121s 283ms/step - loss: 0.5789 - AUC: 0.8813 - accuracy: 0.8314 - precision: 0.7509 - recall: 0.5975 - val_loss: 0.5094 - val_AUC: 0.7866 - val_accuracy: 0.8816 - val_precision: 0.4889 - val_recall: 0.1215\n"
     ]
    }
   ],
   "source": [
    "initial_epochs = 7\n",
    "history_vgg16_2 = model_vgg16.fit(train_ds, epochs = initial_epochs, validation_data = val_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29dcb587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 147/427 [00:43<01:22,  3.41it/s]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "assertion failed: [Unable to decode bytes as JPEG, PNG, GIF, or BMP]\n\t [[{{node decode_image/cond_jpeg/else/_1/decode_image/cond_jpeg/cond_png/else/_20/decode_image/cond_jpeg/cond_png/cond_gif/else/_39/decode_image/cond_jpeg/cond_png/cond_gif/Assert/Assert}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   2101\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2102\u001b[0;31m       \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2103\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2609\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2610\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2611\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6842\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6843\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6844\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: assertion failed: [Unable to decode bytes as JPEG, PNG, GIF, or BMP]\n\t [[{{node decode_image/cond_jpeg/else/_1/decode_image/cond_jpeg/cond_png/else/_20/decode_image/cond_jpeg/cond_png/cond_gif/else/_39/decode_image/cond_jpeg/cond_png/cond_gif/Assert/Assert}}]] [Op:IteratorGetNext]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-f23370d30c81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mnum_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mnum_batch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_batch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m147\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# For Python 3 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    770\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   2103\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2105\u001b[0;31m       \u001b[0mexecutor_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/eager/executor.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;34m\"\"\"Waits for ops dispatched in this executor to finish.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_ExecutorWaitForAllPendingNodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mclear_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: assertion failed: [Unable to decode bytes as JPEG, PNG, GIF, or BMP]\n\t [[{{node decode_image/cond_jpeg/else/_1/decode_image/cond_jpeg/cond_png/else/_20/decode_image/cond_jpeg/cond_png/cond_gif/else/_39/decode_image/cond_jpeg/cond_png/cond_gif/Assert/Assert}}]]"
     ]
    }
   ],
   "source": [
    "# Instantiate an optimizer.\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "# Instantiate a loss function.\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "\n",
    "initial_epochs = 3\n",
    "\n",
    "\n",
    "for epoch in range(initial_epochs):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    step = 0\n",
    "    num_batch = 0\n",
    "    \n",
    "    for x_batch, y_batch in tqdm(train_ds):\n",
    "        num_batch += 1\n",
    "        if num_batch == 147:\n",
    "            continue\n",
    "        step += 1\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model_vgg16(x_batch, training = True)\n",
    "            \n",
    "            loss_value = loss_fn(y_batch, logits)\n",
    "            \n",
    "        grads = tape.gradient(loss_value, model_vgg16.trainable_weights)\n",
    "        \n",
    "        if step % 200 == 0:\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "            print(\"Seen so far: %s samples\" % ((step + 1) * BATCH_SIZE))\n",
    "        #print(num_batch)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "900a5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n"
     ]
    }
   ],
   "source": [
    "print(num_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39c401c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [8.320067405700684, 4.480762481689453, 2.954956293106079], 'AUC': [0.6096783876419067, 0.7112303972244263, 0.744020402431488], 'accuracy': [0.8279834389686584, 0.860082745552063, 0.8741751313209534], 'precision': [0.20700985193252563, 0.2753623127937317, 0.35944700241088867], 'recall': [0.1884346902370453, 0.15154536068439484, 0.15553340315818787], 'val_loss': [5.382885456085205, 3.528676748275757, 2.375058174133301], 'val_AUC': [0.7203466296195984, 0.7822547554969788, 0.7904117107391357], 'val_accuracy': [0.8822381496429443, 0.8854911923408508, 0.8841899633407593], 'val_precision': [0.0, 0.692307710647583, 1.0], 'val_recall': [0.0, 0.049723755568265915, 0.016574585810303688]}\n"
     ]
    }
   ],
   "source": [
    "print(history_vgg16.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d8057a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "14510255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vg_g16_custom_new_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  8193000   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  300300    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  301       \n",
      "=================================================================\n",
      "Total params: 23,208,289\n",
      "Trainable params: 8,493,601\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_vgg16.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dd5de0",
   "metadata": {},
   "source": [
    "## Larger VGG16 retrained on last 4 dense layers + dropout regularization\n",
    "Architecture: \n",
    "last layers after flattening:\n",
    "Dense(2000)-Dropout(0.5)-Dense(800)\n",
    "Dropout(0.5)\n",
    "Dense(100)\n",
    "Dropout(0.5)\n",
    "Dense(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "def6d9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg16_aug = VGG16aug(IMG_WIDTH, IMG_HEIGHT)\n",
    "\n",
    "lr = 3e-4\n",
    "\n",
    "model_vgg16_aug.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = lr),\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(from_logits = False), #BinaryCrossentropy(from_logits = False),\n",
    "    metrics = \n",
    "    METRICS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3117f17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "280/280 [==============================] - 74s 266ms/step - loss: 13.0633 - AUC: 0.5772 - accuracy: 0.8306 - precision: 0.1493 - recall: 0.1087 - val_loss: 7.9799 - val_AUC: 0.7123 - val_accuracy: 0.8822 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/10\n",
      "280/280 [==============================] - 73s 262ms/step - loss: 5.9590 - AUC: 0.6816 - accuracy: 0.8778 - precision: 0.1642 - recall: 0.0219 - val_loss: 4.2896 - val_AUC: 0.7634 - val_accuracy: 0.8822 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/10\n",
      "280/280 [==============================] - 74s 263ms/step - loss: 3.3774 - AUC: 0.7136 - accuracy: 0.8816 - precision: 0.2407 - recall: 0.0259 - val_loss: 2.5200 - val_AUC: 0.7739 - val_accuracy: 0.8822 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/10\n",
      "280/280 [==============================] - 73s 262ms/step - loss: 1.9920 - AUC: 0.7504 - accuracy: 0.8861 - precision: 0.2222 - recall: 0.0060 - val_loss: 1.5473 - val_AUC: 0.7904 - val_accuracy: 0.8822 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/10\n",
      "280/280 [==============================] - 74s 264ms/step - loss: 1.2989 - AUC: 0.7642 - accuracy: 0.8861 - precision: 0.3636 - recall: 0.0199 - val_loss: 1.0665 - val_AUC: 0.7855 - val_accuracy: 0.8822 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/10\n",
      "280/280 [==============================] - 74s 263ms/step - loss: 0.9040 - AUC: 0.7827 - accuracy: 0.8868 - precision: 0.3333 - recall: 0.0090 - val_loss: 0.7761 - val_AUC: 0.8000 - val_accuracy: 0.8822 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/10\n",
      "280/280 [==============================] - 74s 263ms/step - loss: 0.6828 - AUC: 0.8000 - accuracy: 0.8876 - precision: 0.4167 - recall: 0.0050 - val_loss: 0.6088 - val_AUC: 0.8114 - val_accuracy: 0.8822 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/10\n",
      "280/280 [==============================] - 74s 263ms/step - loss: 0.5793 - AUC: 0.7886 - accuracy: 0.8871 - precision: 0.2857 - recall: 0.0040 - val_loss: 0.5611 - val_AUC: 0.7987 - val_accuracy: 0.8822 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/10\n",
      "280/280 [==============================] - 74s 263ms/step - loss: 0.5175 - AUC: 0.7971 - accuracy: 0.8874 - precision: 0.3000 - recall: 0.0030 - val_loss: 0.4950 - val_AUC: 0.8104 - val_accuracy: 0.8822 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/10\n",
      "280/280 [==============================] - 74s 263ms/step - loss: 0.4985 - AUC: 0.7969 - accuracy: 0.8868 - precision: 0.2353 - recall: 0.0040 - val_loss: 0.4788 - val_AUC: 0.8110 - val_accuracy: 0.8822 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "initial_epochs = 10\n",
    "history_vgg16_aug = model_vgg16_aug.fit(train_ds, epochs = initial_epochs, validation_data = val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52696ec",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "872a1418",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [tf.keras.metrics.AUC(name = \"AUC\"), \n",
    "           tf.keras.metrics.BinaryAccuracy(name = \"accuracy\"), \n",
    "           tf.keras.metrics.Precision(name = \"precision\"),\n",
    "           tf.keras.metrics.Recall(name = \"recall\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0e396317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (5.4.1)\n",
      "Requirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from h5py) (1.18.5)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from h5py) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/tensorflow2_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyyaml h5py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dab246e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint  cp-0001.ckpt.data-00000-of-00001  cp-0001.ckpt.index\r\n"
     ]
    }
   ],
   "source": [
    "%ls ./training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de4870e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = './training/cp-{epoch:04d}.ckpt'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9942ecba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training/cp-{epoch:04d}.ckpt'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d4fc6ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpoint_path,\n",
    "    save_weights_only = True,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "173f2236",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.models_resnet import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "55086797",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet = ResNet50(IMG_WIDTH, IMG_HEIGHT)\n",
    "\n",
    "lr = 3e-4\n",
    "\n",
    "model_resnet.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = lr),\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(from_logits = False), #BinaryCrossentropy(from_logits = False),\n",
    "    metrics = \n",
    "    METRICS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad9c8ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427/427 [==============================] - ETA: 0s - loss: 5.5897 - AUC: 0.7470 - accuracy: 0.7615 - precision: 0.5534 - recall: 0.5056\n",
      "Epoch 00001: saving model to ./training/cp-0001.ckpt\n",
      "427/427 [==============================] - 120s 280ms/step - loss: 5.5897 - AUC: 0.7470 - accuracy: 0.7615 - precision: 0.5534 - recall: 0.5056 - val_loss: 2.0145 - val_AUC: 0.7372 - val_accuracy: 0.8803 - val_precision: 0.4211 - val_recall: 0.0442\n"
     ]
    }
   ],
   "source": [
    "initial_epochs = 1\n",
    "history_resnet = model_resnet.fit(train_ds, \n",
    "                                  epochs = initial_epochs, \n",
    "                                  validation_data = val_ds,\n",
    "                                  callbacks = [cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f7e7358c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'cp-0001.ckpt.data-00000-of-00001',\n",
       " 'cp-0001.ckpt.index',\n",
       " 'checkpoint']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "74d36302",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = ResNet50(IMG_WIDTH, IMG_HEIGHT)\n",
    "\n",
    "model_test.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = lr),\n",
    "                  loss = tf.keras.losses.BinaryCrossentropy(from_logits = False),\n",
    "                  metrics = METRICS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8eddbf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427/427 [==============================] - 118s 277ms/step - loss: 5.7625 - AUC: 0.7566 - accuracy: 0.7666 - precision: 0.5636 - recall: 0.5173 - val_loss: 2.1183 - val_AUC: 0.7537 - val_accuracy: 0.8809 - val_precision: 0.4615 - val_recall: 0.0663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff2182703c8>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test.fit(train_ds, \n",
    "               epochs = 1,\n",
    "              validation_data = val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bffd11d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fee11179eb8>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test.load_weights('./training/cp-0001.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5da34133",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model_test.predict(val_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2358d207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21868916],\n",
       "       [0.21557398],\n",
       "       [0.06801223],\n",
       "       ...,\n",
       "       [0.28538123],\n",
       "       [0.24157326],\n",
       "       [0.05410865]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d93b72a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [1 if pred > 0.5 else 0 for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a56c86e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-ded9b5c424b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_labels' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(preds, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e973eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0c25fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ff17ca0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2498209,\n",
       " 0.41986144,\n",
       " 0.027611354,\n",
       " 0.43621403,\n",
       " 0.22604129,\n",
       " 0.20733821,\n",
       " 0.21681795,\n",
       " 0.38893333,\n",
       " 0.25078514,\n",
       " 0.11390686,\n",
       " 0.22863618,\n",
       " 0.24871348,\n",
       " 0.11963376,\n",
       " 0.22439787,\n",
       " 0.063260466,\n",
       " 0.16480902,\n",
       " 0.4495684,\n",
       " 0.09077853,\n",
       " 0.30585864,\n",
       " 0.09247598,\n",
       " 0.21381044,\n",
       " 0.10715521,\n",
       " 0.6064059,\n",
       " 0.2184623,\n",
       " 0.40134698,\n",
       " 0.4524548,\n",
       " 0.32343972,\n",
       " 0.2370961,\n",
       " 0.25960422,\n",
       " 0.3989988,\n",
       " 0.22453652,\n",
       " 0.13603091,\n",
       " 0.27753204,\n",
       " 0.069263235,\n",
       " 0.1774761,\n",
       " 0.10067225,\n",
       " 0.15456748,\n",
       " 0.2249928,\n",
       " 0.4444993,\n",
       " 0.16446537,\n",
       " 0.22192557,\n",
       " 0.3563604,\n",
       " 0.5549331,\n",
       " 0.23882696,\n",
       " 0.27427083,\n",
       " 0.1822735,\n",
       " 0.19573769,\n",
       " 0.28317595,\n",
       " 0.36189765,\n",
       " 0.15554951,\n",
       " 0.3154702,\n",
       " 0.104643896,\n",
       " 0.061719056,\n",
       " 0.08205519,\n",
       " 0.09664791,\n",
       " 0.06494268,\n",
       " 0.09770874,\n",
       " 0.04931894,\n",
       " 0.09944096,\n",
       " 0.10936917,\n",
       " 0.021138346,\n",
       " 0.02666021,\n",
       " 0.10216459,\n",
       " 0.085646994,\n",
       " 0.07294874,\n",
       " 0.15757206,\n",
       " 0.07233473,\n",
       " 0.055593334,\n",
       " 0.055077795,\n",
       " 0.06080877,\n",
       " 0.052905016,\n",
       " 0.1197291,\n",
       " 0.03451443,\n",
       " 0.04564494,\n",
       " 0.13280088,\n",
       " 0.034184355,\n",
       " 0.053755194,\n",
       " 0.037427038,\n",
       " 0.06933452,\n",
       " 0.036272164,\n",
       " 0.06416606,\n",
       " 0.048470065,\n",
       " 0.10018086,\n",
       " 0.22763702,\n",
       " 0.29363692,\n",
       " 0.082640395,\n",
       " 0.1599506,\n",
       " 0.07826516,\n",
       " 0.049217105,\n",
       " 0.6390896,\n",
       " 0.057913702,\n",
       " 0.17492974,\n",
       " 0.27553472,\n",
       " 0.12443451,\n",
       " 0.72460574,\n",
       " 0.22635858,\n",
       " 0.18935977,\n",
       " 0.202568,\n",
       " 0.29848632,\n",
       " 0.11455434,\n",
       " 0.3457514,\n",
       " 0.10255707,\n",
       " 0.35650384,\n",
       " 0.10852342,\n",
       " 0.19964503,\n",
       " 0.15764071,\n",
       " 0.08098317,\n",
       " 0.3936289,\n",
       " 0.40222135,\n",
       " 0.38074845,\n",
       " 0.15590917,\n",
       " 0.06887834,\n",
       " 0.3786363,\n",
       " 0.044719122,\n",
       " 0.24509394,\n",
       " 0.12263636,\n",
       " 0.06201012,\n",
       " 0.1346631,\n",
       " 0.16431949,\n",
       " 0.058452807,\n",
       " 0.16105664,\n",
       " 0.101432145,\n",
       " 0.21587244,\n",
       " 0.12880258,\n",
       " 0.13334112,\n",
       " 0.10679073,\n",
       " 0.36912704,\n",
       " 0.34372082,\n",
       " 0.20156391,\n",
       " 0.111872464,\n",
       " 0.12546189,\n",
       " 0.30855128,\n",
       " 0.14860576,\n",
       " 0.21221699,\n",
       " 0.49606523,\n",
       " 0.11934344,\n",
       " 0.61921066,\n",
       " 0.23034021,\n",
       " 0.05343153,\n",
       " 0.1100741,\n",
       " 0.15573573,\n",
       " 0.07788273,\n",
       " 0.056069285,\n",
       " 0.1627236,\n",
       " 0.16381352,\n",
       " 0.11873677,\n",
       " 0.23855421,\n",
       " 0.048219215,\n",
       " 0.095140934,\n",
       " 0.06301144,\n",
       " 0.4295352,\n",
       " 0.27966556,\n",
       " 0.10720335,\n",
       " 0.078359514,\n",
       " 0.15083422,\n",
       " 0.17120378,\n",
       " 0.18303093,\n",
       " 0.15669572,\n",
       " 0.37229133,\n",
       " 0.06512788,\n",
       " 0.24164897,\n",
       " 0.24958727,\n",
       " 0.46937105,\n",
       " 0.052513413,\n",
       " 0.16956314,\n",
       " 0.30972815,\n",
       " 0.26429874,\n",
       " 0.16394798,\n",
       " 0.24075134,\n",
       " 0.46768716,\n",
       " 0.041142993,\n",
       " 0.19738336,\n",
       " 0.12539724,\n",
       " 0.20886981,\n",
       " 0.18475969,\n",
       " 0.085721254,\n",
       " 0.27556586,\n",
       " 0.2485888,\n",
       " 0.065933056,\n",
       " 0.12410644,\n",
       " 0.041871257,\n",
       " 0.17808673,\n",
       " 0.52402735,\n",
       " 0.3201826,\n",
       " 0.2934479,\n",
       " 0.2909514,\n",
       " 0.08139146,\n",
       " 0.111021735,\n",
       " 0.13276058,\n",
       " 0.055399615,\n",
       " 0.1501179,\n",
       " 0.2630759,\n",
       " 0.20468211,\n",
       " 0.1607232,\n",
       " 0.23249981,\n",
       " 0.2655948,\n",
       " 0.13591021,\n",
       " 0.118520476,\n",
       " 0.028047387,\n",
       " 0.04008331,\n",
       " 0.044187695,\n",
       " 0.5521301,\n",
       " 0.19572233,\n",
       " 0.08210983,\n",
       " 0.061003387,\n",
       " 0.14016709,\n",
       " 0.20999226,\n",
       " 0.30598137,\n",
       " 0.15117772,\n",
       " 0.03337623,\n",
       " 0.089970365,\n",
       " 0.34536472,\n",
       " 0.06523941,\n",
       " 0.040795594,\n",
       " 0.014008593,\n",
       " 0.4052037,\n",
       " 0.1611172,\n",
       " 0.07656521,\n",
       " 0.13556412,\n",
       " 0.24538188,\n",
       " 0.28800333,\n",
       " 0.108406596,\n",
       " 0.21718502,\n",
       " 0.29487026,\n",
       " 0.05342056,\n",
       " 0.16684896,\n",
       " 0.24039002,\n",
       " 0.051679995,\n",
       " 0.21036683,\n",
       " 0.10197239,\n",
       " 0.10316759,\n",
       " 0.18307152,\n",
       " 0.19401982,\n",
       " 0.2181743,\n",
       " 0.40450686,\n",
       " 0.14685537,\n",
       " 0.27449638,\n",
       " 0.39344457,\n",
       " 0.37107673,\n",
       " 0.07181022,\n",
       " 0.21877024,\n",
       " 0.3137709,\n",
       " 0.25280407,\n",
       " 0.1861937,\n",
       " 0.32092646,\n",
       " 0.2446903,\n",
       " 0.2074178,\n",
       " 0.07853301,\n",
       " 0.21011138,\n",
       " 0.1088202,\n",
       " 0.09480011,\n",
       " 0.23632547,\n",
       " 0.30211294,\n",
       " 0.30505845,\n",
       " 0.2847188,\n",
       " 0.23301384,\n",
       " 0.13062705,\n",
       " 0.14436503,\n",
       " 0.12141254,\n",
       " 0.11837064,\n",
       " 0.19153418,\n",
       " 0.3115624,\n",
       " 0.14322254,\n",
       " 0.2522716,\n",
       " 0.09982629,\n",
       " 0.28247887,\n",
       " 0.37607065,\n",
       " 0.14999999,\n",
       " 0.09635257,\n",
       " 0.1090777,\n",
       " 0.3241988,\n",
       " 0.2195724,\n",
       " 0.21004367,\n",
       " 0.08806195,\n",
       " 0.17904648,\n",
       " 0.107938424,\n",
       " 0.23550169,\n",
       " 0.042790238,\n",
       " 0.13340695,\n",
       " 0.023880858,\n",
       " 0.1654236,\n",
       " 0.022607105,\n",
       " 0.1223855,\n",
       " 0.052000698,\n",
       " 0.05896752,\n",
       " 0.030535731,\n",
       " 0.07157792,\n",
       " 0.071014464,\n",
       " 0.07430215,\n",
       " 0.0512898,\n",
       " 0.11401531,\n",
       " 0.04699517,\n",
       " 0.124483526,\n",
       " 0.009151639,\n",
       " 0.09027482,\n",
       " 0.28408816,\n",
       " 0.43227884,\n",
       " 0.023344845,\n",
       " 0.30371514,\n",
       " 0.2657353,\n",
       " 0.096440494,\n",
       " 0.23067756,\n",
       " 0.26569515,\n",
       " 0.032531194,\n",
       " 0.074922964,\n",
       " 0.22070496,\n",
       " 0.11271835,\n",
       " 0.040787693,\n",
       " 0.052018065,\n",
       " 0.03248084,\n",
       " 0.2389259,\n",
       " 0.10346717,\n",
       " 0.034690496,\n",
       " 0.15077157,\n",
       " 0.22921793,\n",
       " 0.24335995,\n",
       " 0.09211469,\n",
       " 0.09771284,\n",
       " 0.29615882,\n",
       " 0.12276438,\n",
       " 0.5040625,\n",
       " 0.0280482,\n",
       " 0.04693106,\n",
       " 0.19804747,\n",
       " 0.037136815,\n",
       " 0.20847167,\n",
       " 0.051217858,\n",
       " 0.5437616,\n",
       " 0.1463162,\n",
       " 0.21854444,\n",
       " 0.084470734,\n",
       " 0.17700951,\n",
       " 0.0750859,\n",
       " 0.20978238,\n",
       " 0.043695584,\n",
       " 0.17678705,\n",
       " 0.2657616,\n",
       " 0.06066446,\n",
       " 0.24262585,\n",
       " 0.116397366,\n",
       " 0.15709431,\n",
       " 0.057718523,\n",
       " 0.11999606,\n",
       " 0.2312867,\n",
       " 0.08535156,\n",
       " 0.2697781,\n",
       " 0.017181879,\n",
       " 0.03557378,\n",
       " 0.18442276,\n",
       " 0.1226781,\n",
       " 0.17231531,\n",
       " 0.105325125,\n",
       " 0.22548938,\n",
       " 0.24807025,\n",
       " 0.32538754,\n",
       " 0.09192853,\n",
       " 0.18853329,\n",
       " 0.015449339,\n",
       " 0.10695765,\n",
       " 0.31757748,\n",
       " 0.15252367,\n",
       " 0.03960161,\n",
       " 0.049250886,\n",
       " 0.08471333,\n",
       " 0.035308037,\n",
       " 0.23256932,\n",
       " 0.28995785,\n",
       " 0.035983082,\n",
       " 0.2728653,\n",
       " 0.2968101,\n",
       " 0.20756462,\n",
       " 0.17736377,\n",
       " 0.20163985,\n",
       " 0.2341389,\n",
       " 0.41581497,\n",
       " 0.18279602,\n",
       " 0.27815062,\n",
       " 0.0011688983,\n",
       " 0.043142766,\n",
       " 0.011393999,\n",
       " 0.2488578,\n",
       " 0.31419274,\n",
       " 0.26436135,\n",
       " 0.003310325,\n",
       " 0.03679883,\n",
       " 0.0030418946,\n",
       " 0.011289899,\n",
       " 0.3583474,\n",
       " 0.0113049885,\n",
       " 0.0017985599,\n",
       " 0.18886831,\n",
       " 0.37845555,\n",
       " 0.009724774,\n",
       " 0.0015406521,\n",
       " 0.07231781,\n",
       " 0.010645196,\n",
       " 0.055056106,\n",
       " 0.25808698,\n",
       " 0.008350959,\n",
       " 0.09725861,\n",
       " 0.20343682,\n",
       " 0.23867546,\n",
       " 0.020935046,\n",
       " 0.07847372,\n",
       " 0.010506839,\n",
       " 0.0036029252,\n",
       " 0.0074129784,\n",
       " 0.28257465,\n",
       " 0.17657155,\n",
       " 0.0046157767,\n",
       " 0.07064892,\n",
       " 0.030409282,\n",
       " 0.15329397,\n",
       " 0.0023194884,\n",
       " 0.104972534,\n",
       " 0.20783743,\n",
       " 0.0033150872,\n",
       " 0.033321816,\n",
       " 0.0011413982,\n",
       " 0.006615315,\n",
       " 0.02134573,\n",
       " 0.2277836,\n",
       " 0.015088534,\n",
       " 0.004676169,\n",
       " 0.0025557822,\n",
       " 0.00457358,\n",
       " 0.00989728,\n",
       " 0.12470666,\n",
       " 0.0002696074,\n",
       " 0.10100557,\n",
       " 0.36122012,\n",
       " 0.017465038,\n",
       " 0.2629604,\n",
       " 0.3198228,\n",
       " 0.049614638,\n",
       " 0.03087892,\n",
       " 0.0050067576,\n",
       " 0.07863392,\n",
       " 0.26632556,\n",
       " 0.027831517,\n",
       " 0.00056336034,\n",
       " 0.15965255,\n",
       " 0.0014679017,\n",
       " 0.19092369,\n",
       " 0.010013817,\n",
       " 0.021090437,\n",
       " 0.009456421,\n",
       " 0.3202167,\n",
       " 0.1156322,\n",
       " 0.3459737,\n",
       " 0.14342816,\n",
       " 0.06852615,\n",
       " 0.007896925,\n",
       " 0.041422646,\n",
       " 0.0025851128,\n",
       " 0.13921097,\n",
       " 0.0041315486,\n",
       " 0.2617346,\n",
       " 0.031947516,\n",
       " 0.13910268,\n",
       " 0.04116682,\n",
       " 0.016935788,\n",
       " 0.1062179,\n",
       " 0.14795743,\n",
       " 0.0057030837,\n",
       " 0.0046772365,\n",
       " 0.18047413,\n",
       " 0.044392038,\n",
       " 0.03360564,\n",
       " 0.013354696,\n",
       " 0.07337488,\n",
       " 0.44110033,\n",
       " 0.14661293,\n",
       " 0.0034512496,\n",
       " 0.008629844,\n",
       " 0.27838475,\n",
       " 0.056393202,\n",
       " 0.086634785,\n",
       " 0.0064205513,\n",
       " 0.13119204,\n",
       " 0.01856878,\n",
       " 0.010022059,\n",
       " 0.23470415,\n",
       " 0.0050514666,\n",
       " 0.21341601,\n",
       " 0.1904936,\n",
       " 0.0014709724,\n",
       " 0.13090593,\n",
       " 0.024064275,\n",
       " 0.02378303,\n",
       " 0.20154008,\n",
       " 0.2293513,\n",
       " 0.00038238193,\n",
       " 0.011544718,\n",
       " 0.11692394,\n",
       " 0.22995888,\n",
       " 0.0022268211,\n",
       " 0.07696705,\n",
       " 0.42837322,\n",
       " 0.017743338,\n",
       " 0.117250375,\n",
       " 0.016388414,\n",
       " 0.33349884,\n",
       " 0.0011325981,\n",
       " 0.002161286,\n",
       " 0.30629745,\n",
       " 0.18565129,\n",
       " 0.004993492,\n",
       " 0.1744024,\n",
       " 0.0022012817,\n",
       " 0.018007075,\n",
       " 0.08532798,\n",
       " 0.11421637,\n",
       " 0.004955925,\n",
       " 0.12353585,\n",
       " 0.15723875,\n",
       " 0.18800622,\n",
       " 0.0041454663,\n",
       " 0.1641246,\n",
       " 0.0006240372,\n",
       " 0.36147952,\n",
       " 0.003473066,\n",
       " 0.079689324,\n",
       " 0.017910449,\n",
       " 0.0239083,\n",
       " 0.04558607,\n",
       " 0.20942615,\n",
       " 0.0012553403,\n",
       " 0.015646499,\n",
       " 0.12582053,\n",
       " 0.19637343,\n",
       " 0.29190993,\n",
       " 0.035717577,\n",
       " 0.15113375,\n",
       " 0.10766314,\n",
       " 0.00341328,\n",
       " 0.0033345183,\n",
       " 0.0032517107,\n",
       " 0.095355734,\n",
       " 0.18295713,\n",
       " 0.0050324304,\n",
       " 0.031788737,\n",
       " 0.1489723,\n",
       " 0.42782712,\n",
       " 0.008202646,\n",
       " 0.0019617707,\n",
       " 0.14944245,\n",
       " 0.01278914,\n",
       " 0.25653982,\n",
       " 0.023731682,\n",
       " 0.10712549,\n",
       " 0.03182854,\n",
       " 0.11067743,\n",
       " 0.0033401356,\n",
       " 0.006468492,\n",
       " 0.07586981,\n",
       " 0.0083341785,\n",
       " 0.14392993,\n",
       " 0.0058644763,\n",
       " 0.14066508,\n",
       " 0.0041739,\n",
       " 0.009965592,\n",
       " 0.0069532846,\n",
       " 0.1312575,\n",
       " 0.019429449,\n",
       " 0.002711352,\n",
       " 0.17218527,\n",
       " 0.011553683,\n",
       " 0.00560609,\n",
       " 0.31552765,\n",
       " 0.01944326,\n",
       " 0.16059381,\n",
       " 0.019937987,\n",
       " 0.012514902,\n",
       " 0.1427381,\n",
       " 0.005854672,\n",
       " 0.14487252,\n",
       " 0.05309981,\n",
       " 0.62205267,\n",
       " 0.005562197,\n",
       " 0.048951216,\n",
       " 0.3352437,\n",
       " 0.0005348983,\n",
       " 0.30197513,\n",
       " 0.0021086019,\n",
       " 0.010780661,\n",
       " 0.006085076,\n",
       " 0.12434685,\n",
       " 0.003632259,\n",
       " 0.0694704,\n",
       " 0.0019788097,\n",
       " 0.07504397,\n",
       " 0.16838484,\n",
       " 0.20145208,\n",
       " 0.15958223,\n",
       " 0.23291668,\n",
       " 0.013681431,\n",
       " 0.16577692,\n",
       " 0.18173064,\n",
       " 0.0068586213,\n",
       " 0.003031113,\n",
       " 0.015973363,\n",
       " 0.055920977,\n",
       " 0.116036296,\n",
       " 0.121512465,\n",
       " 0.4590968,\n",
       " 0.010938251,\n",
       " 0.005752267,\n",
       " 0.030591777,\n",
       " 0.0009124616,\n",
       " 0.18760818,\n",
       " 0.00034250593,\n",
       " 0.0052455305,\n",
       " 0.26422584,\n",
       " 0.0017732893,\n",
       " 0.08750808,\n",
       " 0.107242845,\n",
       " 0.0009111454,\n",
       " 0.009841437,\n",
       " 0.1248729,\n",
       " 0.022142634,\n",
       " 0.034853194,\n",
       " 0.0014955848,\n",
       " 0.058257602,\n",
       " 0.06727356,\n",
       " 0.02427012,\n",
       " 0.36376002,\n",
       " 0.08979674,\n",
       " 0.11294189,\n",
       " 0.22343072,\n",
       " 0.21629088,\n",
       " 0.009927823,\n",
       " 0.0034569434,\n",
       " 0.017449751,\n",
       " 0.26018888,\n",
       " 0.07222729,\n",
       " 0.006665836,\n",
       " 0.015255283,\n",
       " 0.11635895,\n",
       " 0.0024536394,\n",
       " 0.14420941,\n",
       " 0.18460266,\n",
       " 0.034125518,\n",
       " 0.37133187,\n",
       " 0.23589143,\n",
       " 0.17670953,\n",
       " 0.20561548,\n",
       " 0.1835346,\n",
       " 0.13174812,\n",
       " 0.13817944,\n",
       " 0.015994685,\n",
       " 0.2877897,\n",
       " 0.051993057,\n",
       " 0.15931587,\n",
       " 0.045350745,\n",
       " 0.017502258,\n",
       " 0.14220652,\n",
       " 0.0022886873,\n",
       " 0.059631538,\n",
       " 0.009297342,\n",
       " 0.0031017943,\n",
       " 0.01007362,\n",
       " 0.22729161,\n",
       " 0.16106726,\n",
       " 0.030746719,\n",
       " 0.058535133,\n",
       " 0.039295394,\n",
       " 0.29661292,\n",
       " 0.008581257,\n",
       " 0.005752913,\n",
       " 0.14126286,\n",
       " 0.006724457,\n",
       " 0.09122562,\n",
       " 0.11410368,\n",
       " 0.025789393,\n",
       " 0.49255583,\n",
       " 0.00074823684,\n",
       " 0.46080568,\n",
       " 0.0012247319,\n",
       " 0.22875156,\n",
       " 0.3562235,\n",
       " 0.07411812,\n",
       " 0.002090922,\n",
       " 0.057062633,\n",
       " 0.013890702,\n",
       " 0.012361212,\n",
       " 0.14090303,\n",
       " 0.18963875,\n",
       " 0.36417052,\n",
       " 0.12119968,\n",
       " 0.00208724,\n",
       " 0.35624343,\n",
       " 0.21816519,\n",
       " 0.04138617,\n",
       " 0.1859114,\n",
       " 0.014561627,\n",
       " 0.23956029,\n",
       " 0.0034794838,\n",
       " 0.33883378,\n",
       " 0.010390025,\n",
       " 0.04898455,\n",
       " 0.05350308,\n",
       " 0.3320475,\n",
       " 0.004762413,\n",
       " 0.026559012,\n",
       " 0.0022987046,\n",
       " 0.005244294,\n",
       " 0.19233552,\n",
       " 0.02877111,\n",
       " 0.02765377,\n",
       " 0.2930376,\n",
       " 0.0049174028,\n",
       " 0.41298935,\n",
       " 0.0031582774,\n",
       " 0.017556729,\n",
       " 0.004639877,\n",
       " 0.076220796,\n",
       " 0.009801631,\n",
       " 0.021448867,\n",
       " 0.00090796826,\n",
       " 0.00559049,\n",
       " 0.13685922,\n",
       " 0.20976824,\n",
       " 0.07151164,\n",
       " 0.3345992,\n",
       " 0.008388093,\n",
       " 0.22347867,\n",
       " 0.0075218356,\n",
       " 0.2770747,\n",
       " 0.34579858,\n",
       " 0.0005556822,\n",
       " 0.0013969276,\n",
       " 0.0672376,\n",
       " 0.08320369,\n",
       " 0.05262285,\n",
       " 0.02832934,\n",
       " 0.09042054,\n",
       " 0.0072770314,\n",
       " 0.14162013,\n",
       " 0.050947335,\n",
       " 0.5037362,\n",
       " 0.16828604,\n",
       " 0.14272115,\n",
       " 0.013262314,\n",
       " 0.20202392,\n",
       " 0.0015428088,\n",
       " 0.008479949,\n",
       " 0.312423,\n",
       " 0.0037309793,\n",
       " 0.005757942,\n",
       " 0.19090918,\n",
       " 0.119964376,\n",
       " 0.154858,\n",
       " 0.0035669717,\n",
       " 0.16206014,\n",
       " 0.093176685,\n",
       " 0.31663695,\n",
       " 0.011418398,\n",
       " 0.006200099,\n",
       " 0.02290111,\n",
       " 0.020310985,\n",
       " 0.11379069,\n",
       " 0.25129887,\n",
       " 0.024200201,\n",
       " 0.0077487472,\n",
       " 0.006815193,\n",
       " 0.07040468,\n",
       " 0.002742535,\n",
       " 0.15160911,\n",
       " 0.0057725045,\n",
       " 0.0074712085,\n",
       " 0.00141651,\n",
       " 0.0008180891,\n",
       " 0.031855598,\n",
       " 0.38666895,\n",
       " 0.001775765,\n",
       " 0.004965352,\n",
       " 0.004406286,\n",
       " 0.23373508,\n",
       " 0.03144071,\n",
       " 0.0008185414,\n",
       " 0.029717347,\n",
       " 0.008765746,\n",
       " 0.1278339,\n",
       " 0.2910778,\n",
       " 0.0067840656,\n",
       " 0.16852717,\n",
       " 0.17212649,\n",
       " 0.001282863,\n",
       " 0.31440425,\n",
       " 0.29339284,\n",
       " 0.24918015,\n",
       " 0.00404246,\n",
       " 0.008031273,\n",
       " 0.0057647047,\n",
       " 0.38757855,\n",
       " 0.23372711,\n",
       " 0.006511672,\n",
       " 0.0051073334,\n",
       " 0.24012482,\n",
       " 0.07423627,\n",
       " 0.16184902,\n",
       " 0.08272962,\n",
       " 0.014490977,\n",
       " 0.011198203,\n",
       " 0.0068703177,\n",
       " 0.054033365,\n",
       " 0.33684757,\n",
       " 0.2511074,\n",
       " 0.075532615,\n",
       " 0.1490659,\n",
       " 0.31387895,\n",
       " 0.0007298635,\n",
       " 0.08731371,\n",
       " 0.005561179,\n",
       " 0.035645623,\n",
       " 0.001313251,\n",
       " 0.013208022,\n",
       " 0.0147304265,\n",
       " 0.01327144,\n",
       " 0.12855119,\n",
       " 0.0007226604,\n",
       " 0.06921893,\n",
       " 0.10270395,\n",
       " 0.002958157,\n",
       " 0.10742648,\n",
       " 0.037335336,\n",
       " 0.0033709365,\n",
       " 0.062976986,\n",
       " 0.01029441,\n",
       " 0.009150662,\n",
       " 0.002688424,\n",
       " 0.007443897,\n",
       " 0.2853606,\n",
       " 0.14982764,\n",
       " 0.008732526,\n",
       " 0.005514538,\n",
       " 0.11127164,\n",
       " 0.01059254,\n",
       " 0.0010681502,\n",
       " 0.0075190202,\n",
       " 0.2971107,\n",
       " 0.06233155,\n",
       " 0.0044704424,\n",
       " 0.0030843152,\n",
       " 0.012105146,\n",
       " 0.11549337,\n",
       " 0.0024396807,\n",
       " 0.02717595,\n",
       " 0.008336338,\n",
       " 0.10376461,\n",
       " 0.0025129952,\n",
       " 0.0070570265,\n",
       " 0.053871203,\n",
       " 0.4872274,\n",
       " 0.17037784,\n",
       " 0.2278305,\n",
       " 0.067676745,\n",
       " 0.17713882,\n",
       " 0.00257795,\n",
       " 0.40848246,\n",
       " 0.02753181,\n",
       " 0.019964118,\n",
       " 0.17421985,\n",
       " 0.101967566,\n",
       " 0.0039272327,\n",
       " 0.015305124,\n",
       " 0.019712023,\n",
       " 0.12726983,\n",
       " 0.00887315,\n",
       " 0.0019295105,\n",
       " 0.004911079,\n",
       " 0.0035455315,\n",
       " 0.17397797,\n",
       " 0.013564191,\n",
       " 0.002037373,\n",
       " 0.38348666,\n",
       " 0.28118873,\n",
       " 0.002413409,\n",
       " 0.0022179163,\n",
       " 0.16212684,\n",
       " 0.030249767,\n",
       " 0.008590499,\n",
       " 0.006267401,\n",
       " 0.075601496,\n",
       " 0.0033340822,\n",
       " 0.01284045,\n",
       " 0.0022192863,\n",
       " 0.0024080318,\n",
       " 0.122260116,\n",
       " 0.0019381117,\n",
       " 0.09502669,\n",
       " 0.0012585854,\n",
       " 0.104876176,\n",
       " 0.029503563,\n",
       " 0.23576632,\n",
       " 0.09305378,\n",
       " 0.34516472,\n",
       " 0.105562225,\n",
       " 0.15691774,\n",
       " 0.20355071,\n",
       " 0.01379785,\n",
       " 0.06250171,\n",
       " 0.018360114,\n",
       " 0.3183084,\n",
       " 0.001033369,\n",
       " 0.07371408,\n",
       " 0.0048981444,\n",
       " 0.027112637,\n",
       " 0.2594493,\n",
       " 0.004155873,\n",
       " 0.03824869,\n",
       " 0.19009696,\n",
       " 0.003022899,\n",
       " 0.0021800045,\n",
       " 0.018102853,\n",
       " 0.030227926,\n",
       " 0.2523832,\n",
       " 0.33885974,\n",
       " 0.051624577,\n",
       " 0.019099662,\n",
       " 0.011857086,\n",
       " 0.33832127,\n",
       " 0.014644713,\n",
       " 0.10099411,\n",
       " 0.0026054631,\n",
       " 0.0032019445,\n",
       " 0.25539538,\n",
       " 0.004858317,\n",
       " 0.0049805427,\n",
       " 0.017504513,\n",
       " 0.1519657,\n",
       " 0.22406676,\n",
       " 0.010736539,\n",
       " 0.2978073,\n",
       " 0.24932182,\n",
       " 0.081190966,\n",
       " 0.008102368,\n",
       " 0.10371258,\n",
       " 0.13467166,\n",
       " 0.19424681,\n",
       " 0.01908605,\n",
       " 0.06331094,\n",
       " 0.23424894,\n",
       " 0.0886601,\n",
       " 0.17598209,\n",
       " 0.0036468357,\n",
       " 0.18549451,\n",
       " 0.054937005,\n",
       " 0.21441795,\n",
       " 0.007916395,\n",
       " 0.0023324639,\n",
       " 0.0689939,\n",
       " 0.025659425,\n",
       " 0.07357563,\n",
       " 0.017602148,\n",
       " 0.08832245,\n",
       " 0.0052446993,\n",
       " 0.023120701,\n",
       " 0.064528465,\n",
       " 0.022997262,\n",
       " 0.0063998387,\n",
       " 0.030145222,\n",
       " 0.03996795,\n",
       " 0.006485387,\n",
       " 0.06322061,\n",
       " 0.1928176,\n",
       " 0.35873717,\n",
       " 0.011396045,\n",
       " 0.098041914,\n",
       " 0.09503519,\n",
       " 0.0044213473,\n",
       " 0.025209483,\n",
       " 0.010392262,\n",
       " 0.0008396147,\n",
       " 0.05756403,\n",
       " 0.008861646,\n",
       " 0.017170737,\n",
       " 0.13338527,\n",
       " 0.13498147,\n",
       " 0.015885923,\n",
       " 0.46276787,\n",
       " 0.005581217,\n",
       " 0.045718428,\n",
       " 0.039425477,\n",
       " 0.01140072,\n",
       " 0.054594845,\n",
       " 0.020614052,\n",
       " 0.13768868,\n",
       " 0.19696602,\n",
       " 0.06715747,\n",
       " 0.00391177,\n",
       " 0.18079832,\n",
       " 0.008911363,\n",
       " 0.000989018,\n",
       " 0.026211595,\n",
       " 0.29137692,\n",
       " 0.0076548047,\n",
       " 0.15469359,\n",
       " 0.008129606,\n",
       " ...]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_resnet = model_resnet.predict(val_ds)\n",
    "preds_resnet = [prob[0] for prob in preds_resnet]\n",
    "preds_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7936845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850c2c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88890a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_files_test = os.listdir('data/processed/test/benign')\n",
    "num_benign_test = len(lst_files_test)\n",
    "lst_files_malignant_test = os.listdir('data/processed/test/malignant')\n",
    "num_malignant_test = len(lst_files_malignant_test)\n",
    "lst_files_test.extend(lst_files_malignant_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3bb117c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b1ba03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6faba6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resnet = pd.DataFrame({'img_name': lst_files_test, 'prob': preds_resnet})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1501046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resnet.to_csv('predictions/preds_resnet.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df70a27f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957b7162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3545e490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34900ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0740da81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fa1caec",
   "metadata": {},
   "source": [
    "# EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17ee4de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.models_efficient_net import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63ce42a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [tf.keras.metrics.AUC(name = \"AUC\"), \n",
    "           tf.keras.metrics.BinaryAccuracy(name = \"accuracy\"), \n",
    "           tf.keras.metrics.Precision(name = \"precision\"),\n",
    "           tf.keras.metrics.Recall(name = \"recall\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8039dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_effnet = EfficientNet(IMG_WIDTH, IMG_HEIGHT)\n",
    "\n",
    "lr = 3e-4\n",
    "\n",
    "model_effnet.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = lr),\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(from_logits = False), #BinaryCrossentropy(from_logits = False),\n",
    "    metrics = \n",
    "    METRICS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17984f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "427/427 [==============================] - 483s 1s/step - loss: 13.7568 - AUC: 0.7688 - accuracy: 0.7695 - precision: 0.6122 - recall: 0.4883 - val_loss: 6.1214 - val_AUC: 0.7734 - val_accuracy: 0.8640 - val_precision: 0.3600 - val_recall: 0.1989\n",
      "Epoch 2/10\n",
      "427/427 [==============================] - 114s 268ms/step - loss: 4.1020 - AUC: 0.8454 - accuracy: 0.8104 - precision: 0.7210 - recall: 0.5297 - val_loss: 2.5181 - val_AUC: 0.7571 - val_accuracy: 0.8855 - val_precision: 0.7273 - val_recall: 0.0442\n",
      "Epoch 3/10\n",
      "427/427 [==============================] - 114s 267ms/step - loss: 1.8481 - AUC: 0.8504 - accuracy: 0.8140 - precision: 0.7326 - recall: 0.5316 - val_loss: 1.1798 - val_AUC: 0.7805 - val_accuracy: 0.8835 - val_precision: 0.5556 - val_recall: 0.0552\n",
      "Epoch 4/10\n",
      "427/427 [==============================] - 114s 267ms/step - loss: 0.9947 - AUC: 0.8523 - accuracy: 0.8190 - precision: 0.7451 - recall: 0.5399 - val_loss: 0.6765 - val_AUC: 0.7806 - val_accuracy: 0.8822 - val_precision: 0.5000 - val_recall: 0.1160\n",
      "Epoch 5/10\n",
      "427/427 [==============================] - 114s 267ms/step - loss: 0.6713 - AUC: 0.8558 - accuracy: 0.8171 - precision: 0.7418 - recall: 0.5350 - val_loss: 0.5033 - val_AUC: 0.7754 - val_accuracy: 0.8770 - val_precision: 0.4394 - val_recall: 0.1602\n",
      "Epoch 6/10\n",
      "427/427 [==============================] - 114s 267ms/step - loss: 0.5584 - AUC: 0.8543 - accuracy: 0.8182 - precision: 0.7465 - recall: 0.5339 - val_loss: 0.4374 - val_AUC: 0.7859 - val_accuracy: 0.8835 - val_precision: 0.5208 - val_recall: 0.1381\n",
      "Epoch 7/10\n",
      "427/427 [==============================] - 114s 267ms/step - loss: 0.5177 - AUC: 0.8553 - accuracy: 0.8174 - precision: 0.7467 - recall: 0.5290 - val_loss: 0.4145 - val_AUC: 0.7843 - val_accuracy: 0.8855 - val_precision: 0.6190 - val_recall: 0.0718\n",
      "Epoch 8/10\n",
      "427/427 [==============================] - 114s 267ms/step - loss: 0.5092 - AUC: 0.8512 - accuracy: 0.8146 - precision: 0.7500 - recall: 0.5094 - val_loss: 0.4180 - val_AUC: 0.7865 - val_accuracy: 0.8829 - val_precision: 0.5098 - val_recall: 0.1436\n",
      "Epoch 9/10\n",
      "427/427 [==============================] - 114s 267ms/step - loss: 0.5010 - AUC: 0.8520 - accuracy: 0.8155 - precision: 0.7413 - recall: 0.5269 - val_loss: 0.3927 - val_AUC: 0.7833 - val_accuracy: 0.8868 - val_precision: 0.8182 - val_recall: 0.0497\n",
      "Epoch 10/10\n",
      "427/427 [==============================] - 114s 267ms/step - loss: 0.4992 - AUC: 0.8524 - accuracy: 0.8171 - precision: 0.7472 - recall: 0.5266 - val_loss: 0.3998 - val_AUC: 0.7748 - val_accuracy: 0.8796 - val_precision: 0.4600 - val_recall: 0.1271\n"
     ]
    }
   ],
   "source": [
    "initial_epochs = 10\n",
    "history_effnet = model_effnet.fit(train_ds, epochs = initial_epochs, validation_data = val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1d5fcb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions on val_ds\n",
    "\n",
    "preds_effnet = model_effnet.predict(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f84be896",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_effnet = [prob[0] for prob in preds_effnet]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3e62af34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_effnet = pd.DataFrame({'img_name': lst_files_test, 'prob': preds_effnet})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b21ec0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_effnet.to_csv('predictions/preds_effnet.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5576ab3",
   "metadata": {},
   "source": [
    "# Comparing ROC curves, AUC scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a46e94fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curve\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# utils:\n",
    "\n",
    "def get_predictions(data, model):\n",
    "    predictions = np.array([])\n",
    "    test_labels = np.array([])\n",
    "    num_batches = 0\n",
    "    val_examples = 1537 \n",
    "    \n",
    "    for batch, y in data:\n",
    "        predictions = np.append(predictions, model.predict(batch))\n",
    "        test_labels = np.append(test_labels, y)\n",
    "        num_batches += 1\n",
    "        if num_batches == math.ceil(val_examples / BATCH_SIZE):\n",
    "            break\n",
    "    return test_labels, predictions\n",
    "\n",
    "def plot_roc(data, model):\n",
    "    \n",
    "    test_labels, predictions = get_predictions(data, model)\n",
    "\n",
    "    #pred_classes = [1 if val > 0.5 else 0 for val in predictions ]\n",
    "    fp, tp, _ = roc_curve(test_labels, predictions)\n",
    "    plt.plot(fp*100, tp*100)\n",
    "    plt.xlabel(\"FP rate\")\n",
    "    plt.ylabel(\"TP rate\")\n",
    "    #plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9abb21b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc(val_ds, model_resnet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4924905a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc(val_ds, model_effnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bcb901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a530c27",
   "metadata": {},
   "source": [
    "## TPR, FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "95c9a8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06741527]\n",
      " [0.11062878]\n",
      " [0.03968845]\n",
      " ...\n",
      " [0.22215804]\n",
      " [0.00605361]\n",
      " [0.0033764 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe72c51a6d8>]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model_effnet.predict(val_ds)\n",
    "print(predictions)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6369ddcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "493108a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-daddc2b0e57e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'get_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "test_labels, predictions = get_predictions(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "68ef5412",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-943923e11db0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc = roc_auc_score(test_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db67d940",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(predictions))\n",
    "pred_classes = [1 if val > 0.1 else 0 for val in predictions ]\n",
    "len(pred_classes)\n",
    "\n",
    "# compute fpr and tpr for threshold 0.5\n",
    "FP, TP, P, N = 0, 0, 0, 0\n",
    "\n",
    "for (true_label, pred_label) in zip(test_labels, pred_classes):\n",
    "    if true_label == 0: # not sick\n",
    "        N += 1\n",
    "        if pred_label == 1:\n",
    "            FP += 1\n",
    "    else: # true_label = 1 (sick)\n",
    "        P += 1\n",
    "        if pred_label == 1:\n",
    "            TP += 1\n",
    "\n",
    "FPR = FP / N\n",
    "TPR = TP / P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6901c2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what percentage of positive people will be classified as negative?\n",
    "# = FN / P \n",
    "FN = P - TP\n",
    "print(f\"Percentage of positive people who will be wrongly classified as negative: {round(FN / P * 100, 2)}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b49220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FPR = FP / N\n",
    "\n",
    "print(f\"Percentage of negative people who will be wrongly classified as positive: {round(FPR, 2)}%.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a152c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do:\n",
    "# data augmentation, skin tone / hair / brightness ... \n",
    "# crop images \n",
    "# larger model, different architecture\n",
    "# regularization\n",
    "# tuning pars: learning rate, \n",
    "# increase image resolution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca9635bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_test_labels(data):\n",
    "    \n",
    "    test_labels = np.array([])\n",
    "    num_batches = 0\n",
    "    val_examples = 1537 \n",
    "    \n",
    "    for batch, y in data:\n",
    "        print(batch[0][0][0][0])\n",
    "        test_labels = np.append(test_labels, y)\n",
    "        num_batches += 1\n",
    "        if num_batches == math.ceil(val_examples / BATCH_SIZE):\n",
    "            break\n",
    "    return test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a77facf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3.0403547, shape=(), dtype=float32)\n",
      "tf.Tensor(173.91853, shape=(), dtype=float32)\n",
      "tf.Tensor(19.932978, shape=(), dtype=float32)\n",
      "tf.Tensor(110.91853, shape=(), dtype=float32)\n",
      "tf.Tensor(134.85333, shape=(), dtype=float32)\n",
      "tf.Tensor(142.24, shape=(), dtype=float32)\n",
      "tf.Tensor(157.80711, shape=(), dtype=float32)\n",
      "tf.Tensor(137.55356, shape=(), dtype=float32)\n",
      "tf.Tensor(10.973556, shape=(), dtype=float32)\n",
      "tf.Tensor(19.921423, shape=(), dtype=float32)\n",
      "tf.Tensor(215.5975, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(232.5, shape=(), dtype=float32)\n",
      "tf.Tensor(192.5, shape=(), dtype=float32)\n",
      "tf.Tensor(171.5, shape=(), dtype=float32)\n",
      "tf.Tensor(232.5, shape=(), dtype=float32)\n",
      "tf.Tensor(40.0, shape=(), dtype=float32)\n",
      "tf.Tensor(203.0, shape=(), dtype=float32)\n",
      "tf.Tensor(179.0, shape=(), dtype=float32)\n",
      "tf.Tensor(177.5, shape=(), dtype=float32)\n",
      "tf.Tensor(56.5, shape=(), dtype=float32)\n",
      "tf.Tensor(182.0, shape=(), dtype=float32)\n",
      "tf.Tensor(232.0, shape=(), dtype=float32)\n",
      "tf.Tensor(245.0, shape=(), dtype=float32)\n",
      "tf.Tensor(168.5, shape=(), dtype=float32)\n",
      "tf.Tensor(213.5, shape=(), dtype=float32)\n",
      "tf.Tensor(216.0, shape=(), dtype=float32)\n",
      "tf.Tensor(195.0, shape=(), dtype=float32)\n",
      "tf.Tensor(221.5, shape=(), dtype=float32)\n",
      "tf.Tensor(186.0, shape=(), dtype=float32)\n",
      "tf.Tensor(222.5, shape=(), dtype=float32)\n",
      "tf.Tensor(189.0, shape=(), dtype=float32)\n",
      "tf.Tensor(145.5, shape=(), dtype=float32)\n",
      "tf.Tensor(181.5, shape=(), dtype=float32)\n",
      "tf.Tensor(228.0, shape=(), dtype=float32)\n",
      "tf.Tensor(232.0, shape=(), dtype=float32)\n",
      "tf.Tensor(211.5, shape=(), dtype=float32)\n",
      "tf.Tensor(218.5, shape=(), dtype=float32)\n",
      "tf.Tensor(219.0, shape=(), dtype=float32)\n",
      "tf.Tensor(200.0, shape=(), dtype=float32)\n",
      "tf.Tensor(151.0, shape=(), dtype=float32)\n",
      "tf.Tensor(172.5, shape=(), dtype=float32)\n",
      "tf.Tensor(3.5, shape=(), dtype=float32)\n",
      "tf.Tensor(147.67853, shape=(), dtype=float32)\n",
      "tf.Tensor(116.706665, shape=(), dtype=float32)\n",
      "tf.Tensor(11.776089, shape=(), dtype=float32)\n",
      "tf.Tensor(193.0, shape=(), dtype=float32)\n",
      "tf.Tensor(242.5, shape=(), dtype=float32)\n",
      "tf.Tensor(176.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_labels = get_test_labels(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08db47d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = pd.DataFrame({'labels':test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "10137705",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.to_csv('evaluate/test_labels.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf79ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6112a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f3632a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
